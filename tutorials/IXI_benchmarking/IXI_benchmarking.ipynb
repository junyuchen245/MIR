{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66488a23",
   "metadata": {},
   "source": [
    "import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "from torchvision import transforms\n",
    "\n",
    "from MIR.models import SpatialTransformer, EncoderFeatureExtractor, SITReg, VFA, TransMorphTVF, TransMorph, convex_adam_MIND\n",
    "from MIR.models.SITReg import ReLUFactory, GroupNormalizerFactory\n",
    "from MIR.models.SITReg.composable_mapping import DataFormat\n",
    "from MIR.models.SITReg.deformation_inversion_layer.fixed_point_iteration import (\n",
    "    AndersonSolver,\n",
    "    AndersonSolverArguments,\n",
    "    MaxElementWiseAbsStopCriterion,\n",
    "    RelativeL2ErrorStopCriterion,\n",
    ")\n",
    "import MIR.models.convexAdam.configs_ConvexAdam_MIND as CONFIGS_CVXAdam\n",
    "import MIR.models.configs_TransMorph as configs_TransMorph\n",
    "import MIR.models.configs_VFA as CONFIGS_VFA\n",
    "from data import datasets, trans\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955123e",
   "metadata": {},
   "source": [
    "Define image size and dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eca22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, D = 160, 192, 224\n",
    "data_dir = './IXI_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbb27a",
   "metadata": {},
   "source": [
    "Initialize models\n",
    "We begin with TransMorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108ecaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmorph_model():\n",
    "    scale_factor = 1\n",
    "    config = configs_TransMorph.get_3DTransMorph3Lvl_config()\n",
    "    config.img_size = (H//scale_factor, W//scale_factor, D//scale_factor)\n",
    "    config.window_size = (H // 64, W // 64, D // 64)\n",
    "    config.out_chan = 3\n",
    "    print(config)\n",
    "    TM_model = TransMorph(config).cuda('cuda:0')\n",
    "    return TM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f212c",
   "metadata": {},
   "source": [
    "Then TransMorph-TVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092531b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmorphTVF_model():\n",
    "    scale_factor = 2\n",
    "    config = configs_TransMorph.get_3DTransMorph3Lvl_config()\n",
    "    config.img_size = (H//scale_factor, W//scale_factor, D//scale_factor)\n",
    "    config.window_size = (H // 64, W // 64, D // 64)\n",
    "    config.out_chan = 3\n",
    "    print(config)\n",
    "    TMTVF_model = TransMorphTVF(config, time_steps=7).cuda('cuda:0')\n",
    "    return TMTVF_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512641e9",
   "metadata": {},
   "source": [
    "Then VFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78536f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfa_model():\n",
    "    scale_factor = 1\n",
    "    config = CONFIGS_VFA.get_VFA_default_config()\n",
    "    config.img_size = (H//scale_factor, W//scale_factor, D//scale_factor)\n",
    "    print(config)\n",
    "    VFA_model = VFA(config, device='cuda:0')\n",
    "    return VFA_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bbd665",
   "metadata": {},
   "source": [
    "Then SITReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(INPUT_SHAPE) -> SITReg:\n",
    "    \"\"\"Create SITReg model from config\"\"\"\n",
    "    feature_extractor = EncoderFeatureExtractor(\n",
    "            n_input_channels=1,\n",
    "            activation_factory=ReLUFactory(),\n",
    "            n_features_per_resolution=[12, 16, 32, 64, 128, 128],\n",
    "            n_convolutions_per_resolution=[2, 2, 2, 2, 2, 2],\n",
    "            input_shape=INPUT_SHAPE,\n",
    "            normalizer_factory=GroupNormalizerFactory(2),\n",
    "        ).cuda()\n",
    "    AndersonSolver_forward = AndersonSolver(\n",
    "        MaxElementWiseAbsStopCriterion(min_iterations=2, max_iterations=50, threshold=1e-2),\n",
    "        AndersonSolverArguments(memory_length=4),\n",
    "    )\n",
    "    AndersonSolver_backward = AndersonSolver(\n",
    "        RelativeL2ErrorStopCriterion(min_iterations=2, max_iterations=50, threshold=1e-2),\n",
    "        AndersonSolverArguments(memory_length=4),\n",
    "    )\n",
    "    network = SITReg(\n",
    "        feature_extractor=feature_extractor,\n",
    "        n_transformation_convolutions_per_resolution=[2, 2, 2, 2, 2, 2],\n",
    "        n_transformation_features_per_resolution=[12, 64, 128, 256, 256, 256],\n",
    "        max_control_point_multiplier=0.99,\n",
    "        affine_transformation_type=None,\n",
    "        input_voxel_size=(1.0, 1.0, 1.0),\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        transformation_downsampling_factor=(1.0, 1.0, 1.0),\n",
    "        forward_fixed_point_solver=AndersonSolver_forward,\n",
    "        backward_fixed_point_solver=AndersonSolver_backward,\n",
    "        activation_factory=ReLUFactory(),\n",
    "        normalizer_factory=GroupNormalizerFactory(4),\n",
    "            ).cuda()\n",
    "    return network\n",
    "\n",
    "def sitreg_model():\n",
    "    return create_model((H, W, D)).cuda('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81ded3",
   "metadata": {},
   "source": [
    "Then ConvexAdam-MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e10755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexadam_model():\n",
    "    config = CONFIGS_CVXAdam.get_ConvexAdam_MIND_brain_default_config()\n",
    "    model = convex_adam_MIND\n",
    "    return {'model': model, 'config': config}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e27d4",
   "metadata": {},
   "source": [
    "Then deedsBCV (this is only available on Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from MIR.utils.deedsbcv_binary import get_deedsbcv_executable\n",
    "\n",
    "def load_deedsBCV_flow(flow_prefix: str) -> torch.Tensor:\n",
    "    disp_ux = nib.load(flow_prefix + \"_ux.nii.gz\").get_fdata()[None, ...]\n",
    "    disp_vx = nib.load(flow_prefix + \"_vx.nii.gz\").get_fdata()[None, ...]\n",
    "    disp_wx = nib.load(flow_prefix + \"_wx.nii.gz\").get_fdata()[None, ...]\n",
    "    disp_arr = np.concatenate([disp_vx, disp_ux, disp_wx], axis=0)\n",
    "    disp_tensor = torch.from_numpy(disp_arr).float().unsqueeze(0)\n",
    "    return disp_tensor\n",
    "\n",
    "deeds_exe = get_deedsbcv_executable(\"deedsBCV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f68d8",
   "metadata": {},
   "source": [
    "Creating model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf754671",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'TransMorph': transmorph_model,\n",
    "               'TransMorphTVF': transmorphTVF_model,\n",
    "               'VFA': vfa_model,\n",
    "               'SITReg': sitreg_model,\n",
    "               'ConvexAdam-MIND': convexadam_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702277c6",
   "metadata": {},
   "source": [
    "Checking if dataset is available, if not grab from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e658dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-VQewCVNj5eTtc3eQGhTM2yXBQmgm8Ol\n",
      "From (redirected): https://drive.google.com/uc?id=1-VQewCVNj5eTtc3eQGhTM2yXBQmgm8Ol&confirm=t&uuid=e766a6ce-2983-4985-accf-dbdc2bbd34d3\n",
      "To: /scratch/jchen/python_projects/custom_packages/MIR/tutorials/IXI_benchmarking/IXI_data.zip\n",
      "100%|██████████| 1.54G/1.54G [02:15<00:00, 11.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    import gdown\n",
    "    # download model\n",
    "    file_id = '1-VQewCVNj5eTtc3eQGhTM2yXBQmgm8Ol'\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, 'IXI_data.zip', quiet=False)\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('IXI_data.zip', 'r') as zip:\n",
    "        zip.extractall('./')\n",
    "    os.remove('IXI_data.zip')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise ValueError('Data directory not found and download failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = data_dir + 'test/'\n",
    "atlas_dir = data_dir + 'atlas.pkl'\n",
    "test_composed = transforms.Compose([\n",
    "        trans.Seg_norm(),\n",
    "        trans.NumpyType((np.float32, np.int16)),\n",
    "    ])\n",
    "test_set = datasets.IXIBrainInferDataset(glob.glob(test_dir + '*.pkl'), atlas_dir, transforms=test_composed)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff334ef",
   "metadata": {},
   "source": [
    "Initialize inference pipeline for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd955ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_trans = SpatialTransformer((H, W, D)).cuda()\n",
    "\n",
    "def inference(model_name, model, moving, fixed):\n",
    "    if model_name == \"TransMorph\" or model_name == 'VFA':\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            moving = moving.cuda()\n",
    "            fixed = fixed.cuda()\n",
    "            flow = model((moving, fixed))\n",
    "    elif model_name == \"TransMorphTVF\":\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            moving = F.avg_pool3d(moving, 2).cuda()\n",
    "            fixed = F.avg_pool3d(fixed, 2).cuda()\n",
    "            flow = model((moving, fixed))\n",
    "            flow = F.interpolate(flow, size=(H, W, D), mode='trilinear', align_corners=True) * 2.0\n",
    "    elif model_name == \"SITReg\":\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            moving = moving.cuda()\n",
    "            fixed = fixed.cuda()\n",
    "            mapping_pair = model(moving, fixed, mappings_for_levels=((0, False),))[0]\n",
    "            flow = mapping_pair.forward_mapping.sample(data_format=DataFormat.voxel_displacements()).generate_values()\n",
    "    elif model_name == \"ConvexAdam\":\n",
    "        moving = moving.cuda()\n",
    "        fixed = fixed.cuda()\n",
    "        convexadam = model()['model']\n",
    "        config = model()['config']\n",
    "        flow = convexadam(moving, fixed, config)\n",
    "    elif model_name == 'deedsBCV':\n",
    "        os.mkdir('temp_deeds/', exist_ok=True)\n",
    "        x_path = \"temp_deeds/moving.nii.gz\"\n",
    "        y_path = \"temp_deeds/fixed.nii.gz\"\n",
    "        out_prefix = \"temp_deeds/dense_disp\"\n",
    "\n",
    "        nib.Nifti1Image(moving[0, 0].detach().cpu().numpy(), np.eye(4)).to_filename(x_path)\n",
    "        nib.Nifti1Image(fixed[0, 0].detach().cpu().numpy(), np.eye(4)).to_filename(y_path)\n",
    "\n",
    "        cmd = f\"{deeds_exe} -F {y_path} -M {x_path} -O {out_prefix} -G 6x5x4x3x2 -L 6x5x4x3x2 -Q 5x4x3x2x1\"\n",
    "        os.system(cmd)\n",
    "        flow = load_deedsBCV_flow(out_prefix).cuda()\n",
    "        os.system(\"rm -rf temp_deeds/\")\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8360ed",
   "metadata": {},
   "source": [
    "Iterating through models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIR.accuracy_measures import calc_J_i, calc_Jstar_1, calc_Jstar_2, calc_jac_dets, get_identity_grid, calc_measurements, dice_val_substruct\n",
    "\n",
    "def to_cuda(batch):\n",
    "    return [t.cuda(non_blocking=True) for t in batch]\n",
    "\n",
    "for model_name, model_func in models_dict.items():\n",
    "    model = model_func()\n",
    "    print(f'Evaluating model: {model_name}')\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        x, y, x_seg, y_seg = to_cuda(sample)\n",
    "        x = x.float()\n",
    "        y = y.float()\n",
    "        flow = inference(model_name, model, x, y)\n",
    "        x_seg_oh = F.one_hot(x_seg.long(), num_classes=46)\n",
    "        x_seg_oh = torch.squeeze(x_seg_oh, 1)\n",
    "        x_seg_oh = x_seg_oh.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        x_segs = []\n",
    "        for i in range(46):\n",
    "            def_seg = spatial_trans(x_seg_oh[:, i:i + 1, ...].float(), flow.float())\n",
    "            x_segs.append(def_seg)\n",
    "        x_segs = torch.cat(x_segs, dim=1)\n",
    "        def_out = torch.argmax(x_segs, dim=1, keepdim=True)\n",
    "        del x_segs, x_seg_oh\n",
    "        \n",
    "        mask = x.detach().cpu().numpy()[0, 0, 1:-1, 1:-1, 1:-1]\n",
    "        mask = mask > 0\n",
    "        disp_field = flow.cpu().detach().numpy()[0]\n",
    "        trans_ = disp_field + get_identity_grid(disp_field)\n",
    "        jac_dets = calc_jac_dets(trans_)\n",
    "        non_diff_voxels, non_diff_tetrahedra, non_diff_volume = calc_measurements(jac_dets, mask)\n",
    "        total_voxels = np.sum(mask)\n",
    "        ndv = non_diff_volume / total_voxels * 100\n",
    "        ndp = non_diff_voxels / total_voxels * 100\n",
    "        \n",
    "        line = dice_val_substruct(def_out.long(), y_seg.long(), stdy_idx)\n",
    "        line = line +','+str(ndv)+','+str(ndp)\n",
    "        #csv_writter(line, 'Quantitative_Results/' + model_folder[:-1])\n",
    "    del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
